{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05d553a",
   "metadata": {},
   "source": [
    "# Part 12: 多重表征索引\n",
    "主要的思路：对文档进行摘要，通过摘要进行索引。可以通过相似的逻辑，扩展对原文档的多种索引方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3be0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# 加载网页数据\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\")\n",
    "docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d31d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过llm对文档进行摘要\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model, ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_url = os.getenv('API_URL')\n",
    "api_key = os.getenv('API_KEY')\n",
    "model_name = os.getenv('MODEL')\n",
    "llm = init_chat_model(\n",
    "    model_provider=\"openai\",  # 避免langchain根据模型名自动选择供应商\n",
    "    model=model_name,\n",
    "    # temperature=0.0,\n",
    "    api_key=api_key,\n",
    "    base_url=api_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0b41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93edd44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liutingting\\AppData\\Local\\Temp\\ipykernel_11820\\1688003342.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(collection_name=\"summaries\",\n",
      "f:\\project\\rag-from-scratch\\.venv\\Lib\\site-packages\\chromadb\\execution\\expression\\operator.py:225: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"Field proxy for building Where conditions with operator overloading.\n"
     ]
    }
   ],
   "source": [
    "# 使用摘要进行索引\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from ark_embedding import ArkEmbeddings\n",
    "\n",
    "\n",
    "embd = ArkEmbeddings(\n",
    "    model=os.getenv(\"ALIYUN_EMBEDDING_MODEL\"),\n",
    "    api_key=os.getenv(\"ALIYUN_API_KEY\"),\n",
    "    api_url=os.getenv(\"ALIYUN_API_URL\"),\n",
    "    batch_size=10\n",
    ")\n",
    "# 向量化并存储\n",
    "vectorstore = Chroma(collection_name=\"summaries\",\n",
    "                     embedding_function=embd)\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 构建retriever, 通过id_key关联向量和doc\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# 与摘要关联的doc\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# 分别添加向量和文档\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5216bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': '625d221f-ab8e-48eb-866f-7dd58760a6d0'}, page_content='Of course. Here is a summary of the document \"LLM Powered Autonomous Agents\" by Lilian Weng.\\n\\n### Document Summary\\n\\nThis comprehensive blog post explores the architecture, components, and real-world applications of autonomous agents powered by Large Language Models (LLMs). It frames the LLM as the core \"brain\" of an agent system, which is augmented by three key components to overcome its inherent limitations.\\n\\n#### Core Components of an LLM Agent:\\n\\n1.  **Planning:** The agent breaks down complex tasks into smaller, manageable subgoals and can self-reflect to learn from mistakes.\\n    *   **Task Decomposition:** Techniques like Chain-of-Thought (CoT) and Tree of Thoughts are used to break problems into steps.\\n    *   **Self-Reflection:** Frameworks like **ReAct** (Reason + Act) and **Reflexion** allow the agent to critique its past actions, learn from failures, and refine its future strategy.\\n\\n2.  **Memory:** The agent uses different types of memory to retain information.\\n    *   **Short-Term Memory:** Analogous to the model\\'s limited context window, used for in-context learning.\\n    *   **Long-Term Memory:** An external vector database (e.g., using **FAISS, ScaNN, or HNSW** for fast retrieval) that allows the agent to store and recall vast amounts of information over time.\\n\\n3.  **Tool Use:** The agent learns to call external APIs and tools to access information not contained in its pre-trained weights (e.g., current data, calculators, code execution, search engines).\\n    *   Projects like **MRKL**, **Toolformer**, and **HuggingGPT** demonstrate this capability, where the LLM acts as a router to select the right expert tool for a given task.\\n\\n#### Case Studies & Examples:\\n\\n*   **Scientific Discovery (ChemCrow):** An agent equipped with 13 expert chemistry tools that outperformed raw GPT-4 in designing and planning complex experiments, as judged by human experts.\\n*   **Generative Agents:** A simulation where 25 LLM-powered agents live in a sandbox environment (like The Sims), exhibiting believable human-like behaviors, forming relationships, and coordinating social events based on memory and reflection.\\n*   **Proof-of-Concepts:** The post examines the inner workings of popular early agent projects like **AutoGPT** and **GPT-Engineer**, highlighting their use of prompting, task clarification, and code generation.\\n\\n#### Key Challenges:\\n\\nThe post concludes by outlining several significant challenges that remain:\\n*   **Finite Context Length:** The LLM\\'s limited context window restricts historical detail and complex planning.\\n*   **Difficulty with Long-Term Planning:** Agents struggle to adjust plans robustly in the face of unexpected errors.\\n*   **Unreliability of Natural Language Interface:** Outputs can be inconsistently formatted or unpredictable, requiring extensive parsing and error-handling code.\\n\\nIn essence, the document provides a detailed technical blueprint for building LLM-based autonomous agents, illustrating their potential with real-world examples while frankly discussing the current limitations that need to be overcome.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 匹配相似摘要\n",
    "query = \"Memory in agents\"\n",
    "sub_docs = vectorstore.similarity_search(query, k=1)\n",
    "sub_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c4bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liutingting\\AppData\\Local\\Temp\\ipykernel_11820\\1266415567.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query, n_results=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three:\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过匹配摘要，检索相似文档\n",
    "retrieved_docs = retriever.get_relevant_documents(query, n_results=1)\n",
    "retrieved_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac9521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c14b48",
   "metadata": {},
   "source": [
    "# Part 13: RAPTOR\n",
    "Recursive Abstractive Processing for Tree-Organized Retrieval  \n",
    "参考代码：https://github.com/parthsarthi03/raptor#  \n",
    "主要的思路：对聚类后的文本块进行摘要并嵌入，递归这个过程，自底向上构建具有树状结构的不同层级摘要和嵌入。在推理时，从该树中进行检索，整合长篇文档中不同抽象层级的信息。 \n",
    "整体的思想，有点类似GraphRAG的分层聚类，获取不同层级的信息，只是GraphRAG是对知识图谱进行操作，而RAPTOR是直接对分块chunk或文档进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5b333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/project/rag-from-scratch/raptor\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = (Path(os.getcwd()).parent / \"raptor\").resolve().as_posix()\n",
    "sys.path.append(project_root)\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f59be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\project\\rag-from-scratch\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-11-21 21:09:28,759 - Loading faiss with AVX2 support.\n",
      "2025-11-21 21:09:28,778 - Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "from raptor import (\n",
    "    BaseSummarizationModel, \n",
    "    BaseQAModel, \n",
    "    BaseEmbeddingModel, \n",
    "    RetrievalAugmentation,\n",
    "    RetrievalAugmentationConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9877e59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac57e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySummarizationModel(BaseSummarizationModel):\n",
    "    def __init__(self, model=os.environ[\"MODEL\"]):\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    # @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "    def summarize(self, context, max_tokens=500, stop_sequence=None):\n",
    "\n",
    "        try:\n",
    "            client = OpenAI(\n",
    "                base_url=os.environ[\"API_URL\"],\n",
    "                api_key=os.environ[\"API_KEY\"],\n",
    "            )\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Write a summary of the following, including as many key details as possible: {context}:\",\n",
    "                    },\n",
    "                ],\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079d9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQAModel(BaseQAModel):\n",
    "    def __init__(self, model=os.environ[\"MODEL\"]):\n",
    "        \"\"\"\n",
    "        Initializes the GPT-3 model with the specified model version.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): The GPT-3 model version to use for generating summaries. Defaults to \"text-davinci-003\".\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.environ[\"API_KEY\"],\n",
    "            base_url=os.environ[\"API_URL\"],\n",
    "        )\n",
    "\n",
    "    # @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "    def answer_question(self, context, question, max_tokens=150, stop_sequence=None):\n",
    "        \"\"\"\n",
    "        Generates a summary of the given context using the GPT-3 model.\n",
    "\n",
    "        Args:\n",
    "            context (str): The text to summarize.\n",
    "            max_tokens (int, optional): The maximum number of tokens in the generated summary. Defaults to 150.\n",
    "            stop_sequence (str, optional): The sequence at which to stop summarization. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated summary.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.completions.create(\n",
    "                prompt=f\"using the folloing information {context}. Answer the following question in less than 5-7 words, if possible: {question}\",\n",
    "                temperature=0,\n",
    "                max_tokens=max_tokens,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                stop=stop_sequence,\n",
    "                model=self.model,\n",
    "            )\n",
    "            return response.choices[0].text.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8058118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark_embedding import ArkEmbeddings\n",
    "\n",
    "\n",
    "class MyEmbeddingModel(BaseEmbeddingModel):\n",
    "    def __init__(self, model=\"text-embedding-ada-002\"):\n",
    "        self.client = ArkEmbeddings(\n",
    "            model=os.getenv(\"ALIYUN_EMBEDDING_MODEL\"),\n",
    "            api_key=os.getenv(\"ALIYUN_API_KEY\"),\n",
    "            api_url=os.getenv(\"ALIYUN_API_URL\"),\n",
    "            batch_size=10\n",
    "        )\n",
    "\n",
    "    # @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "    def create_embedding(self, text):\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        embd = self.client.embed_documents([text])\n",
    "        return embd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485130d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAC = RetrievalAugmentationConfig(\n",
    "    summarization_model=MySummarizationModel(), \n",
    "    qa_model=MyQAModel(), \n",
    "    embedding_model=MyEmbeddingModel()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31fc3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wife of a rich man fell sick, and as she felt that her end\n",
      "was drawing near, she called her only\n"
     ]
    }
   ],
   "source": [
    "# 加载测试用文本\n",
    "with open('data/sample.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0fa7617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 21:09:29,834 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.MySummarizationModel object at 0x0000023FF6AFD820>\n",
      "            Embedding Models: {'EMB': <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-11-21 21:09:29,835 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.MySummarizationModel object at 0x0000023FF6AFD820>\n",
      "            Embedding Models: {'EMB': <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-11-21 21:09:29,836 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.MySummarizationModel object at 0x0000023FF6AFD820>\n",
      "            Embedding Models: {'EMB': <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <__main__.MyQAModel object at 0x0000023FF6AFD070>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-11-21 21:09:29,841 - Creating Leaf Nodes\n",
      "2025-11-21 21:09:30,788 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,798 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,816 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,822 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,894 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,902 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,914 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,920 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,923 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,924 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,934 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,935 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,944 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,949 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:30,999 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,010 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,014 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,020 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,039 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,043 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,051 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,052 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,059 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,062 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,075 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-21 21:09:31,076 - Retrying request to /embeddings in 0.492027 seconds\n",
      "2025-11-21 21:09:31,081 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-21 21:09:31,082 - Retrying request to /embeddings in 0.476246 seconds\n",
      "2025-11-21 21:09:31,088 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-21 21:09:31,088 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-21 21:09:31,089 - Retrying request to /embeddings in 0.490397 seconds\n",
      "2025-11-21 21:09:31,090 - Retrying request to /embeddings in 0.433098 seconds\n",
      "2025-11-21 21:09:31,103 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,109 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,128 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,129 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-21 21:09:31,130 - Retrying request to /embeddings in 0.471577 seconds\n",
      "2025-11-21 21:09:31,135 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,189 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,214 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,654 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,659 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,663 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,675 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,708 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:31,710 - Created 35 Leaf Embeddings\n",
      "2025-11-21 21:09:31,711 - Building All Nodes\n",
      "2025-11-21 21:09:31,721 - Using Cluster TreeBuilder\n",
      "2025-11-21 21:09:31,722 - Constructing Layer 0\n",
      "f:\\project\\rag-from-scratch\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "f:\\project\\rag-from-scratch\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-11-21 21:09:43,914 - Summarization Length: 100\n",
      "2025-11-21 21:09:47,628 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:47,636 - Node Texts Length: 471, Summarized Text Length: 104\n",
      "2025-11-21 21:09:47,821 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:51,207 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:51,210 - Node Texts Length: 298, Summarized Text Length: 100\n",
      "2025-11-21 21:09:51,311 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:54,622 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:54,624 - Node Texts Length: 382, Summarized Text Length: 102\n",
      "2025-11-21 21:09:54,727 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:58,423 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:09:58,425 - Node Texts Length: 676, Summarized Text Length: 100\n",
      "2025-11-21 21:09:58,511 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:01,937 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:01,940 - Node Texts Length: 407, Summarized Text Length: 102\n",
      "2025-11-21 21:10:02,036 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:05,729 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:05,733 - Node Texts Length: 582, Summarized Text Length: 102\n",
      "2025-11-21 21:10:05,826 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:09,395 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:09,396 - Node Texts Length: 465, Summarized Text Length: 100\n",
      "2025-11-21 21:10:09,514 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:09,519 - Constructing Layer 1\n",
      "2025-11-21 21:10:09,521 - Stopping Layer construction: Cannot Create More Layers. Total Layers in tree: 1\n",
      "2025-11-21 21:10:09,525 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# 构建树状检索\n",
    "RA = RetrievalAugmentation(config=RAC)\n",
    "\n",
    "RA.add_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7117dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 21:10:14,259 - Using collapsed_tree\n",
      "2025-11-21 21:10:14,358 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:10:14,473 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/completions \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404\n",
      "Answer:  \n"
     ]
    }
   ],
   "source": [
    "# 从树状检索中查询\n",
    "question = \"How did Cinderella reach her happy ending?\"\n",
    "\n",
    "answer = RA.answer_question(question=question)\n",
    "\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f9bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 21:13:22,049 - Tree successfully saved to data/cinderella\n"
     ]
    }
   ],
   "source": [
    "# 保存结果\n",
    "SAVE_PATH = \"data/cinderella\"\n",
    "RA.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e18b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 21:13:51,952 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.MySummarizationModel object at 0x0000023FF6AFD820>\n",
      "            Embedding Models: {'EMB': <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-11-21 21:13:51,953 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.MySummarizationModel object at 0x0000023FF6AFD820>\n",
      "            Embedding Models: {'EMB': <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-11-21 21:13:51,954 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2025-11-21 21:13:51,954 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.MySummarizationModel object at 0x0000023FF6AFD820>\n",
      "            Embedding Models: {'EMB': <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <__main__.MyEmbeddingModel object at 0x0000023FF6AFE000>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <__main__.MyQAModel object at 0x0000023FF6AFD070>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-11-21 21:13:51,955 - Using collapsed_tree\n",
      "2025-11-21 21:13:52,207 - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-21 21:13:52,317 - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/completions \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404\n",
      "Answer:  \n"
     ]
    }
   ],
   "source": [
    "# 从保存的结果中恢复检索结果\n",
    "RA = RetrievalAugmentation(config=RAC, tree=SAVE_PATH)\n",
    "\n",
    "answer = RA.answer_question(question=question)\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61552c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17a8d9a7",
   "metadata": {},
   "source": [
    "# Part 14: ColBERT\n",
    "介绍资料：https://hackernoon.com/how-colbert-helps-developers-overcome-the-limits-of-rag  \n",
    "论文：https://arxiv.org/abs/2004.12832?ref=hackernoon.com  \n",
    "核心原理：\n",
    "- 通过分词+bert进行向量化（通过双向的transformer编码，得到考虑了上下文的向量）。\n",
    "- 文档和查询都会做相同的处理。\n",
    "- 每个文档的总得分 = 逐个“分词后的查询向量”分别计算与“分词后的文档向量”的最大相似度，并求和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cea599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用专用于colbert的模型\n",
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载wiki的数据\n",
    "import requests\n",
    "\n",
    "def get_wikipedia_page(title: str):\n",
    "    \"\"\"\n",
    "    Retrieve the full text content of a Wikipedia page.\n",
    "\n",
    "    :param title: str - Title of the Wikipedia page.\n",
    "    :return: str - Full text content of the page as raw string.\n",
    "    \"\"\"\n",
    "    # Wikipedia API endpoint\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "    }\n",
    "\n",
    "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
    "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1 (ben@clavie.eu)\"}\n",
    "\n",
    "    response = requests.get(URL, params=params, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extracting page content\n",
    "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
    "    return page[\"extract\"] if \"extract\" in page else None\n",
    "\n",
    "full_document = get_wikipedia_page(\"Hayao_Miyazaki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ffcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立索引\n",
    "RAG.index(\n",
    "    collection=[full_document],\n",
    "    index_name=\"Miyazaki-123\",\n",
    "    max_document_length=180,\n",
    "    split_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b844645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检索\n",
    "results = RAG.search(query=\"What animation studio did Miyazaki found?\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为langchain retriever\n",
    "retriever = RAG.as_langchain_retriever(k=3)\n",
    "retriever.invoke(\"What animation studio did Miyazaki found?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58badb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
