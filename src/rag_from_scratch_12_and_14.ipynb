{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05d553a",
   "metadata": {},
   "source": [
    "# Part 12: 多重表征索引\n",
    "主要的思路：对文档进行摘要，通过摘要进行索引。可以通过相似的逻辑，扩展对原文档的多种索引方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3be0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# 加载网页数据\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\")\n",
    "docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d31d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过llm对文档进行摘要\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model, ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_url = os.getenv('API_URL')\n",
    "api_key = os.getenv('API_KEY')\n",
    "model_name = os.getenv('MODEL')\n",
    "llm = init_chat_model(\n",
    "    model_provider=\"openai\",  # 避免langchain根据模型名自动选择供应商\n",
    "    model=model_name,\n",
    "    # temperature=0.0,\n",
    "    api_key=api_key,\n",
    "    base_url=api_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0b41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93edd44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liutingting\\AppData\\Local\\Temp\\ipykernel_11820\\1688003342.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(collection_name=\"summaries\",\n",
      "f:\\project\\rag-from-scratch\\.venv\\Lib\\site-packages\\chromadb\\execution\\expression\\operator.py:225: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"Field proxy for building Where conditions with operator overloading.\n"
     ]
    }
   ],
   "source": [
    "# 使用摘要进行索引\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from ark_embedding import ArkEmbeddings\n",
    "\n",
    "\n",
    "embd = ArkEmbeddings(\n",
    "    model=os.getenv(\"ALIYUN_EMBEDDING_MODEL\"),\n",
    "    api_key=os.getenv(\"ALIYUN_API_KEY\"),\n",
    "    api_url=os.getenv(\"ALIYUN_API_URL\"),\n",
    "    batch_size=10\n",
    ")\n",
    "# 向量化并存储\n",
    "vectorstore = Chroma(collection_name=\"summaries\",\n",
    "                     embedding_function=embd)\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 构建retriever, 通过id_key关联向量和doc\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# 与摘要关联的doc\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# 分别添加向量和文档\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5216bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': '625d221f-ab8e-48eb-866f-7dd58760a6d0'}, page_content='Of course. Here is a summary of the document \"LLM Powered Autonomous Agents\" by Lilian Weng.\\n\\n### Document Summary\\n\\nThis comprehensive blog post explores the architecture, components, and real-world applications of autonomous agents powered by Large Language Models (LLMs). It frames the LLM as the core \"brain\" of an agent system, which is augmented by three key components to overcome its inherent limitations.\\n\\n#### Core Components of an LLM Agent:\\n\\n1.  **Planning:** The agent breaks down complex tasks into smaller, manageable subgoals and can self-reflect to learn from mistakes.\\n    *   **Task Decomposition:** Techniques like Chain-of-Thought (CoT) and Tree of Thoughts are used to break problems into steps.\\n    *   **Self-Reflection:** Frameworks like **ReAct** (Reason + Act) and **Reflexion** allow the agent to critique its past actions, learn from failures, and refine its future strategy.\\n\\n2.  **Memory:** The agent uses different types of memory to retain information.\\n    *   **Short-Term Memory:** Analogous to the model\\'s limited context window, used for in-context learning.\\n    *   **Long-Term Memory:** An external vector database (e.g., using **FAISS, ScaNN, or HNSW** for fast retrieval) that allows the agent to store and recall vast amounts of information over time.\\n\\n3.  **Tool Use:** The agent learns to call external APIs and tools to access information not contained in its pre-trained weights (e.g., current data, calculators, code execution, search engines).\\n    *   Projects like **MRKL**, **Toolformer**, and **HuggingGPT** demonstrate this capability, where the LLM acts as a router to select the right expert tool for a given task.\\n\\n#### Case Studies & Examples:\\n\\n*   **Scientific Discovery (ChemCrow):** An agent equipped with 13 expert chemistry tools that outperformed raw GPT-4 in designing and planning complex experiments, as judged by human experts.\\n*   **Generative Agents:** A simulation where 25 LLM-powered agents live in a sandbox environment (like The Sims), exhibiting believable human-like behaviors, forming relationships, and coordinating social events based on memory and reflection.\\n*   **Proof-of-Concepts:** The post examines the inner workings of popular early agent projects like **AutoGPT** and **GPT-Engineer**, highlighting their use of prompting, task clarification, and code generation.\\n\\n#### Key Challenges:\\n\\nThe post concludes by outlining several significant challenges that remain:\\n*   **Finite Context Length:** The LLM\\'s limited context window restricts historical detail and complex planning.\\n*   **Difficulty with Long-Term Planning:** Agents struggle to adjust plans robustly in the face of unexpected errors.\\n*   **Unreliability of Natural Language Interface:** Outputs can be inconsistently formatted or unpredictable, requiring extensive parsing and error-handling code.\\n\\nIn essence, the document provides a detailed technical blueprint for building LLM-based autonomous agents, illustrating their potential with real-world examples while frankly discussing the current limitations that need to be overcome.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 匹配相似摘要\n",
    "query = \"Memory in agents\"\n",
    "sub_docs = vectorstore.similarity_search(query, k=1)\n",
    "sub_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c4bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liutingting\\AppData\\Local\\Temp\\ipykernel_11820\\1266415567.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query, n_results=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three:\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过匹配摘要，检索相似文档\n",
    "retrieved_docs = retriever.get_relevant_documents(query, n_results=1)\n",
    "retrieved_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac9521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c14b48",
   "metadata": {},
   "source": [
    "# Part 13: RAPTOR\n",
    "Recursive Abstractive Processing for Tree-Organized Retrieval  \n",
    "参考代码：https://github.com/parthsarthi03/raptor#  \n",
    "主要的思路：对聚类后的文本块进行摘要并嵌入，递归这个过程，自底向上构建具有树状结构的不同层级摘要和嵌入。在推理时，从该树中进行检索，整合长篇文档中不同抽象层级的信息。 \n",
    "整体的思想，有点类似GraphRAG的分层聚类，获取不同层级的信息，只是GraphRAG是对知识图谱进行操作，而RAPTOR是直接对分块chunk或文档进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad94000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wife of a rich man fell sick, and as she felt that her end\n",
      "was drawing near, she called her only\n"
     ]
    }
   ],
   "source": [
    "# 加载测试用文本\n",
    "with open('data/sample.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5b333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/project/rag-from-scratch/raptor\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = (Path(os.getcwd()).parent / \"raptor\").resolve().as_posix()\n",
    "sys.path.append(project_root)\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b9f857",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 构建树形摘要\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mraptor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalAugmentation \n\u001b[32m      5\u001b[39m RA = RetrievalAugmentation()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# construct the tree\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\project\\rag-from-scratch\\raptor\\raptor\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# raptor/__init__.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster_tree_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClusterTreeBuilder, ClusterTreeConfig\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mEmbeddingModels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (BaseEmbeddingModel, OpenAIEmbeddingModel,\n\u001b[32m      4\u001b[39m                               SBertEmbeddingModel)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mFaissRetriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FaissRetriever, FaissRetrieverConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\project\\rag-from-scratch\\raptor\\raptor\\cluster_tree_builder.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Lock\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Set\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClusteringAlgorithm, RAPTOR_Clustering\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TreeBuilder, TreeBuilderConfig\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_structures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node, Tree\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\project\\rag-from-scratch\\raptor\\raptor\\cluster_utils.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtiktoken\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mumap\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmixture\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GaussianMixture\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Initialize logging\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "# 构建树形摘要\n",
    "from raptor import RetrievalAugmentation \n",
    "\n",
    "\n",
    "RA = RetrievalAugmentation()\n",
    "\n",
    "# construct the tree\n",
    "RA.add_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26f2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9de1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9bce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e18b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61552c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17a8d9a7",
   "metadata": {},
   "source": [
    "# Part 14: ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cea599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4157d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ffcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b844645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe8790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58badb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
