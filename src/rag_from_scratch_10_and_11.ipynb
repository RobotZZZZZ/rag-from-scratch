{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f462bc7",
   "metadata": {},
   "source": [
    "# Part 10: Logical and Semantic routing (逻辑和语义路由)\n",
    "由llm进行分类，在rag前，先选择合适的数据库。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aed1ad",
   "metadata": {},
   "source": [
    "## Logical routing (逻辑路由)\n",
    "由llm进行分类，在rag前，路由到合适的数据库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61739b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 定义llm的返回结果\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"将用户的查询路由到最相关的数据源\"\"\"\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose \"\n",
    "    )\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "# 结构化模型的输出，实际上做了两件事：\n",
    "# 1.提示llm输出json format的结果\n",
    "# 2.将llm的输出结果转换为pydantic定义的对象\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 设计提示词，由llm进行数据源的选择\n",
    "system_prompt = (\n",
    "    \"You are an expert at routing a user question to \"\n",
    "    \"the appropriate data source.\"\n",
    "    \"Based on the programming language the question is referring to, \"\n",
    "    \"route it to the relevant data source.\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 定义路由处理链\n",
    "router = (\n",
    "    prompt\n",
    "    | structured_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82527a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RouteQuery(datasource='python_docs')\n"
     ]
    }
   ],
   "source": [
    "# 使用question调用\n",
    "question = \"\"\"Why doesn't the following code work:\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "prompt.invoke(\"french\")\n",
    "\"\"\"\n",
    "result = router.invoke({\"question\": question})\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78e9574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'chain for python_docs'\n"
     ]
    }
   ],
   "source": [
    "# 根据返回的“代码语言”，选择合适的数据库（此处只作示意，没有实现具体的逻辑）\n",
    "def choose_route(result):\n",
    "    if \"python_docs\" in result.datasource.lower():\n",
    "        return \"chain for python_docs\"\n",
    "    elif \"js_docs\" in result.datasource.lower():\n",
    "        return \"chain for js_docs\"\n",
    "    else:\n",
    "        return \"golang_docs\"\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = (\n",
    "    router\n",
    "    | RunnableLambda(choose_route)\n",
    ")\n",
    "final_result = full_chain.invoke({\"question\": question})\n",
    "pprint(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502cd89",
   "metadata": {},
   "source": [
    "## Semantic routing 语义路由\n",
    "根据用户的输入内容，计算query和prompt间的语义相似度，路由到合适的提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ac66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# 两个分别适用于物理、数据场景的提示词\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "from ark_embedding import ArkEmbeddings\n",
    "\n",
    "embd = ArkEmbeddings(\n",
    "    model=os.getenv(\"ALIYUN_EMBEDDING_MODEL\"),\n",
    "    api_key=os.getenv(\"ALIYUN_API_KEY\"),\n",
    "    api_url=os.getenv(\"ALIYUN_API_URL\"),\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "# 将prompt向量化\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embd.embed_documents(prompt_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54facb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "(\"Of course. That's an excellent and fundamental question.\\n\"\n",
      " '\\n'\n",
      " 'In the simplest terms, a **black hole is a region of space where gravity is '\n",
      " 'so intense that nothing, not even light, can escape from it.**\\n'\n",
      " '\\n'\n",
      " \"Let's break that down:\\n\"\n",
      " '\\n'\n",
      " '1.  **The \"Point of No Return\":** The outer boundary of a black hole is '\n",
      " 'called the **event horizon**. Think of it as a one-way door. Once anything—a '\n",
      " 'spaceship, a planet, or a particle of light (a photon)—crosses this '\n",
      " 'boundary, it can never come back out. We cannot see what happens inside, '\n",
      " 'hence the name \"black hole.\"\\n'\n",
      " '\\n'\n",
      " '2.  **Why the Gravity is So Strong:** The extreme gravity comes from an '\n",
      " 'immense amount of mass being crushed into a vanishingly small point at the '\n",
      " 'very center, called a **singularity**. Imagine crushing the entire mass of '\n",
      " 'our Sun into a sphere less than 4 miles across, or the entire Earth into a '\n",
      " 'sphere the size of a marble. This incredible density warps the fabric of '\n",
      " \"space and time itself, according to Einstein's theory of General \"\n",
      " 'Relativity.\\n'\n",
      " '\\n'\n",
      " '3.  **They Are Not Cosmic Vacuum Cleaners:** A common misconception is that '\n",
      " \"black holes suck everything in. They don't. They exert gravity just like any \"\n",
      " 'other mass. If you replaced our Sun with a black hole of the same mass, all '\n",
      " 'the planets would continue to orbit it exactly as they do now (though it '\n",
      " 'would be very dark and cold!). You only get pulled in if you venture too '\n",
      " 'close to the event horizon.\\n'\n",
      " '\\n'\n",
      " 'In short, a black hole is a gravitational pit in the fabric of spacetime so '\n",
      " \"deep that the exit velocity exceeds the speed of light, the universe's \"\n",
      " 'ultimate speed limit.')\n"
     ]
    }
   ],
   "source": [
    "# 将问题路由到合适的prompt,并回答问题\n",
    "def prompt_router(input):\n",
    "    # question向量化\n",
    "    query_embedding = embd.embed_query(input[\"query\"])\n",
    "    # 计算相似度\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    # 选择相似度最高的prompt\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    # 显式完成提示词构建（可选，也可仅返回prompt模板）\n",
    "    prompt = PromptTemplate.from_template(most_similar).invoke(input)\n",
    "    return prompt\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel({\"query\": RunnablePassthrough()})\n",
    "    | RunnableLambda(prompt_router)  # 将获取的“提示词模板+问题”进行拼装，将调用llm\n",
    "    | llm  # 如果不显示进行拼装，实际也可以运行，因为LangChain维护“执行上下文”，自动进行变量回溯查找。\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"What's a black hole?\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18bf4a8",
   "metadata": {},
   "source": [
    "# Part 11: 查询构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c95b26",
   "metadata": {},
   "source": [
    "前提，创建数据库含有元数据。  \n",
    "可以考虑，采用结构化的查询（带过滤条件），查询根据元数据过滤后的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fdd6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube加载失败: HTTP Error 400: Bad Request\n",
      "使用模拟数据代替...\n",
      "使用模拟数据成功!\n",
      "文档数量: 1\n",
      "元数据: {'source': 'https://www.youtube.com/watch?v=pbAd8O1Lvm4', 'title': 'RAG Tutorial Video', 'author': 'Tutorial Channel', 'length': 600, 'view_count': 10000, 'publish_date': '2024-01-15'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.youtube.com/watch?v=pbAd8O1Lvm4',\n",
       " 'title': 'RAG Tutorial Video',\n",
       " 'author': 'Tutorial Channel',\n",
       " 'length': 600,\n",
       " 'view_count': 10000,\n",
       " 'publish_date': '2024-01-15'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "try:\n",
    "    docs = YoutubeLoader.from_youtube_url(\n",
    "        \"https://www.youtube.com/watch?v=pbAd8O1Lvm4\",\n",
    "        add_video_info=True,\n",
    "    ).load()\n",
    "    \n",
    "    print(\"成功加载YouTube字幕数据!\")\n",
    "    print(f\"文档数量: {len(docs)}\")\n",
    "    print(f\"第一个文档的元数据: {docs[0].metadata}\")\n",
    "    print(f\"第一个文档的前200个字符: {docs[0].page_content[:200]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"YouTube加载失败: {e}\")\n",
    "    print(\"使用模拟数据代替...\")\n",
    "    \n",
    "    # 解决方案: 使用模拟的YouTube视频数据\n",
    "    from langchain_core.documents import Document\n",
    "    \n",
    "    # 模拟YouTube视频的字幕数据\n",
    "    mock_transcript = \"\"\"\n",
    "    Welcome to this tutorial on RAG systems. Today we'll discuss how to build \n",
    "    retrieval augmented generation systems from scratch. We'll cover topics like \n",
    "    semantic search, vector embeddings, and how to integrate them with language models.\n",
    "    \n",
    "    First, let's understand what RAG means. RAG stands for Retrieval Augmented Generation.\n",
    "    It's a technique that combines information retrieval with text generation to create\n",
    "    more accurate and informative responses.\n",
    "    \n",
    "    The key components of a RAG system include: document chunking, vector embeddings,\n",
    "    semantic search, and response generation using language models.\n",
    "    \"\"\"\n",
    "    \n",
    "    docs = [Document(\n",
    "        page_content=mock_transcript,\n",
    "        metadata={\n",
    "            \"source\": \"https://www.youtube.com/watch?v=pbAd8O1Lvm4\",\n",
    "            \"title\": \"RAG Tutorial Video\",\n",
    "            \"author\": \"Tutorial Channel\",\n",
    "            \"length\": 600,\n",
    "            \"view_count\": 10000,\n",
    "            \"publish_date\": \"2024-01-15\"\n",
    "        }\n",
    "    )]\n",
    "    \n",
    "    print(\"使用模拟数据成功!\")\n",
    "    print(f\"文档数量: {len(docs)}\")\n",
    "    print(f\"元数据: {docs[0].metadata}\")\n",
    "\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d02809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TutorialSearch(BaseModel):\n",
    "    \"\"\"结构化搜索查询，包含搜索词和过滤条件\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        ...,\n",
    "        description=\"用于语义搜索的主要查询词\",\n",
    "    )\n",
    "    title_search: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"用于标题搜索的查询词\"\n",
    "        ),\n",
    "    )\n",
    "    min_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum view count filter, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    max_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum view count filter, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    earliest_publish_date: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Earliest publish date filter, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    latest_publish_date: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Latest publish date filter, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    min_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum video length in seconds, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    max_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum video length in seconds, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field_name, field_info in self.__class__.model_fields.items():\n",
    "            value = getattr(self, field_name)\n",
    "            if value is not None and value != field_info.default:\n",
    "                print(f\"{field_name}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98bd7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "Given a question, return a database query optimized to retrieve the most relevant results.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "structured_llm = llm.with_structured_output(TutorialSearch)\n",
    "query_analyzer = (\n",
    "    prompt\n",
    "    | structured_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c22188f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: rag from scratch\n",
      "title_search: rag from scratch\n"
     ]
    }
   ],
   "source": [
    "res = query_analyzer.invoke({\"question\": \"rag from scratch\"})\n",
    "res.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e396605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: chat langchain\n",
      "title_search: chat langchain\n",
      "earliest_publish_date: 2023-01-01\n",
      "latest_publish_date: 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"videos on chat langchain published in 2023\"}\n",
    ").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02923cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: chat langchain\n",
      "title_search: chat langchain\n",
      "latest_publish_date: 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"videos that are focused on the topic of chat langchain that are published before 2024\"}\n",
    ").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8b60b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: multi-modal models in agent\n",
      "title_search: multi-modal agent\n",
      "max_length_sec: 300\n"
     ]
    }
   ],
   "source": [
    "res = query_analyzer.invoke(\n",
    "    {\n",
    "        \"question\": \"how to use multi-modal models in an agent, only videos under 5 minutes\"\n",
    "    }\n",
    ")\n",
    "res.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a3b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import (\n",
    "    StructuredQueryOutputParser,\n",
    ")\n",
    "\n",
    "output_parser = StructuredQueryOutputParser.from_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0d5463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.structured_query import (\n",
    "    StructuredQuery, \n",
    "    Comparison, \n",
    "    Operation, \n",
    "    Comparator, \n",
    "    Operator,\n",
    "    FilterDirective\n",
    ")\n",
    "from typing import Optional, List\n",
    "import json\n",
    "\n",
    "class CustomTutorialQueryOutputParser(BaseOutputParser[StructuredQuery]):\n",
    "    \"\"\"自定义输出解析器，将 TutorialSearch 格式转换为 StructuredQuery\"\"\"\n",
    "    \n",
    "    def parse(self, text: str) -> StructuredQuery:\n",
    "        \"\"\"解析 JSON 字符串并转换为 StructuredQuery\"\"\"\n",
    "        try:\n",
    "            # 解析 JSON 数据\n",
    "            data = json.loads(text)\n",
    "            \n",
    "            # 构建查询字符串（主要用于语义搜索）\n",
    "            query = data.get(\"query\", \"\")\n",
    "            \n",
    "            # 构建过滤条件列表\n",
    "            filter_directives: List[FilterDirective] = []\n",
    "            \n",
    "            # 标题搜索 - 使用 CONTAIN 比较\n",
    "            if data.get(\"title_search\"):\n",
    "                filter_directives.append(\n",
    "                    Comparison(\n",
    "                        comparator=Comparator.CONTAIN,\n",
    "                        attribute=\"title\",\n",
    "                        value=data[\"title_search\"]\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            # 观看次数过滤\n",
    "            if data.get(\"min_view_count\") is not None:\n",
    "                filter_directives.append(\n",
    "                    Comparison(\n",
    "                        comparator=Comparator.GTE,\n",
    "                        attribute=\"view_count\",\n",
    "                        value=data[\"min_view_count\"]\n",
    "                    )\n",
    "                )\n",
    "            if data.get(\"max_view_count\") is not None:\n",
    "                filter_directives.append(\n",
    "                    Comparison(\n",
    "                        comparator=Comparator.LT,\n",
    "                        attribute=\"view_count\", \n",
    "                        value=data[\"max_view_count\"]\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            # 发布时间过滤\n",
    "            if data.get(\"earliest_publish_date\"):\n",
    "                filter_directives.append(\n",
    "                    Comparison(\n",
    "                        comparator=Comparator.GTE,\n",
    "                        attribute=\"publish_date\",\n",
    "                        value=data[\"earliest_publish_date\"]\n",
    "                    )\n",
    "                )\n",
    "            if data.get(\"latest_publish_date\"):\n",
    "                filter_directives.append(\n",
    "                    Comparison(\n",
    "                        comparator=Comparator.LT,\n",
    "                        attribute=\"publish_date\",\n",
    "                        value=data[\"latest_publish_date\"]\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            # 视频长度过滤\n",
    "            if data.get(\"min_length_sec\") is not None:\n",
    "                filter_directives.append(\n",
    "                    Comparison(\n",
    "                        comparator=Comparator.GTE,\n",
    "                        attribute=\"length\",\n",
    "                        value=data[\"min_length_sec\"]\n",
    "                    )\n",
    "                )\n",
    "            if data.get(\"max_length_sec\") is not None:\n",
    "                filter_directives.append(\n",
    "                    Comparison(\n",
    "                        comparator=Comparator.LT,\n",
    "                        attribute=\"length\",\n",
    "                        value=data[\"max_length_sec\"]\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            # 如果有多个过滤条件，用 AND 操作组合\n",
    "            filter_expr: Optional[FilterDirective] = None\n",
    "            if len(filter_directives) == 1:\n",
    "                filter_expr = filter_directives[0]\n",
    "            elif len(filter_directives) > 1:\n",
    "                filter_expr = Operation(\n",
    "                    operator=Operator.AND,\n",
    "                    arguments=filter_directives\n",
    "                )\n",
    "            \n",
    "            # 处理 limit（设置为 None，因为我们没有明确的限制）\n",
    "            limit = None\n",
    "            \n",
    "            return StructuredQuery(\n",
    "                query=query,\n",
    "                filter=filter_expr,\n",
    "                limit=limit\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"解析查询时出错: {e}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def from_components(cls) -> \"CustomTutorialQueryOutputParser\":\n",
    "        \"\"\"工厂方法创建解析器实例\"\"\"\n",
    "        return cls()\n",
    "\n",
    "output_parser = CustomTutorialQueryOutputParser.from_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30dbed9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='multi-modal models in agent', filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.CONTAIN: 'contain'>, attribute='title', value='multi-modal agent'), Comparison(comparator=<Comparator.LT: 'lt'>, attribute='length', value=300)]), limit=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_parser = output_parser.invoke(res.model_dump_json())\n",
    "res_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51d677",
   "metadata": {},
   "source": [
    "结构化查询，参考文档：https://python.langchain.com/docs/how_to/self_query/#constructing-from-scratch-with-lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9842097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
