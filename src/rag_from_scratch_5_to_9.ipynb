{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# 加载文档\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b35927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "splits[:3]\n",
    "\n",
    "# 索引\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from ark_embedding import ArkEmbeddings\n",
    "\n",
    "embd = ArkEmbeddings(\n",
    "    model=os.getenv(\"ALIYUN_EMBEDDING_MODEL\"),\n",
    "    api_key=os.getenv(\"ALIYUN_API_KEY\"),\n",
    "    api_url=os.getenv(\"ALIYUN_API_URL\"),\n",
    "    batch_size=10\n",
    ")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embd\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b4fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def retrieve_with_scores(q):\n",
    "    try:\n",
    "        pairs = vectorstore.similarity_search_with_relevance_scores(q)  # 分数越大越相关[0,1]\n",
    "    except Exception:\n",
    "        print(\"Get relevance score failed. current score is distance score.\")\n",
    "        pairs = vectorstore.similarity_search_with_score(q)             # 距离分数，数值越小越相似\n",
    "    docs = []\n",
    "    for doc, score in pairs:\n",
    "        doc.metadata[\"score\"] = float(score)\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "retriever_with_score = RunnableLambda(lambda x: retrieve_with_scores(x)).map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4f715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_func(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "format_docs = RunnableLambda(format_docs_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1715d",
   "metadata": {},
   "source": [
    "## Part 5: Multi Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7329b3e",
   "metadata": {},
   "source": [
    "主要想法：构造多个相似问题，进行全面的检索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1540d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['What is task decomposition for LLM agents?',\n",
      " 'What are the different strategies for breaking down complex tasks for Large '\n",
      " 'Language Model agents?',\n",
      " 'How do LLM-based agents decompose a high-level goal into smaller, executable '\n",
      " 'sub-tasks?',\n",
      " 'Explain the process of task decomposition in the context of autonomous AI '\n",
      " 'agents.',\n",
      " 'What role does planning and step-by-step breakdown play in the functionality '\n",
      " 'of LLM agents?',\n",
      " 'Can you describe methods for hierarchical task decomposition used by '\n",
      " 'advanced language model agents?']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "# 不同视角的multi query\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 构建处理链\n",
    "# generate_queries = (\n",
    "#     prompt_perspectives\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "#     | (lambda x: x.split(\"\\n\"))\n",
    "# )\n",
    "\n",
    "# 构建处理链，用于生成多个query，同时保留原始查询\n",
    "generate_queries = (\n",
    "    RunnableParallel({\n",
    "        \"original\": RunnablePassthrough(),\n",
    "        \"variations\": (\n",
    "            prompt_perspectives\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "            | (lambda x: x.split(\"\\n\"))\n",
    "        )\n",
    "    })\n",
    "    | (lambda x: [x[\"original\"][\"question\"]] + x[\"variations\"])\n",
    ")\n",
    "\n",
    "# 生成多个query\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "multi_queries = generate_queries.invoke({\"question\": question})\n",
    "\n",
    "from pprint import pprint\n",
    "print(len(multi_queries))\n",
    "pprint(multi_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3954e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
      " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
      " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liutingting\\AppData\\Local\\Temp\\ipykernel_18280\\2829956312.py:10: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  unique_union = [loads(unique_doc) for unique_doc in unique_docs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "# 合并多个查询的检索结果\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\"\n",
    "    获取唯一并集\n",
    "    \"\"\"\n",
    "    # 使用dumps和loads将文档转换为字符串进行去重，完成后再转换回文档\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    unique_union = [loads(unique_doc) for unique_doc in unique_docs]\n",
    "    return unique_union\n",
    "\n",
    "# 检索\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = (\n",
    "    generate_queries \n",
    "    | retriever.map() \n",
    "    | get_unique_union\n",
    ")\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)\n",
    "pprint(docs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26db42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the provided context, task decomposition for LLM agents is the '\n",
      " 'process where a large language model (LLM) breaks down a complicated, '\n",
      " 'high-level task into smaller, simpler, and more manageable sub-tasks or '\n",
      " 'steps.\\n'\n",
      " '\\n'\n",
      " 'Key points from the context include:\\n'\n",
      " '*   It is a core component of planning, allowing an agent to handle complex '\n",
      " 'tasks efficiently.\\n'\n",
      " '*   Techniques like Chain of Thought (CoT) instruct the model to \"think step '\n",
      " 'by step\" to perform this decomposition.\\n'\n",
      " '*   More advanced techniques like Tree of Thoughts (ToT) explore multiple '\n",
      " 'reasoning possibilities for each step.\\n'\n",
      " '*   Decomposition can be achieved through simple prompting (e.g., \"Steps for '\n",
      " 'XYZ.\"), using task-specific instructions, or with human input.')\n"
     ]
    }
   ],
   "source": [
    "# RAG\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 回答模板\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 使用多query检索完成回答\n",
    "final_rag_chain = (\n",
    "    {\n",
    "        \"context\": retrieval_chain | format_docs,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = final_rag_chain.invoke({\"question\": question})\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157dd54a",
   "metadata": {},
   "source": [
    "# Part 6: RAG-Fusion(融合)\n",
    "- Forget RAG, the Future is RAG-Fusion: https://medium.com/data-science/forget-rag-the-future-is-rag-fusion-1147298d8ad1  \n",
    "- 作者的github实现仓库：https://github.com/Raudaschl/rag-fusion/blob/master/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae8a20",
   "metadata": {},
   "source": [
    "实现流程：\n",
    "1. 通过 LLM 将用户的查询转换为相似但不同的查询。\n",
    "2. 对原始查询及其新生成的查询执行向量搜索。\n",
    "3. 使用倒数排序融合聚合和优化所有查询的结果。\n",
    "4. 引导LLM生成结果时，考虑了所有查询和重新排序的结果列表（关键点：在提示词中明确告知llm文档是ranked，也就是重要度由高到低）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717b568",
   "metadata": {},
   "source": [
    "倒数排序融合（RRF，Reciprocal Rank Fusion）是一种结合多个搜索结果列表的排名以生成单一、统一排名的技术。RRF的计算公式如下：\n",
    "$$\n",
    "\\mathrm{RRF}_{\\text{score}}(d \\in D) = \\sum_{r \\in R} \\frac{1}{k + r(d)}\n",
    "$$\n",
    "其中$k=60$，r(d)表示对应文档d在其查询下排序（从1开始）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826efa1",
   "metadata": {},
   "source": [
    "![RRF 图](static/rrf.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b899c",
   "metadata": {},
   "source": [
    "## 提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a787f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Provide these alternative questions separated by newlines. Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32946027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['What is task decomposition for LLM agents?',\n",
      " 'What is task decomposition in the context of LLM agents?',\n",
      " 'How do large language models break down complex tasks?',\n",
      " 'What are the methods and techniques for task decomposition with AI agents?',\n",
      " 'Why is task decomposition important for autonomous LLM agents?']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 构建处理链 - 保留原始查询\n",
    "generate_queries = (\n",
    "    RunnableParallel({\n",
    "        \"original\": RunnablePassthrough(),\n",
    "        \"variations\": (\n",
    "            prompt_rag_fusion\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "            | (lambda x: x.split(\"\\n\"))\n",
    "        )\n",
    "    })\n",
    "    | (lambda x: [x[\"original\"][\"question\"]] + x[\"variations\"])\n",
    ")\n",
    "\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "multi_queries = generate_queries.invoke({\"question\": question})\n",
    "\n",
    "from pprint import pprint\n",
    "print(len(multi_queries))\n",
    "pprint(multi_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f684f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'score': 0.5758502166824937}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
      "  0.016666666666666666),\n",
      " (Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'score': 0.5434629767064793}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
      "  0.016666666666666666),\n",
      " (Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'score': 0.5981592600957346}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
      "  0.016666666666666666)]\n"
     ]
    }
   ],
   "source": [
    "# 倒排融合\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"\n",
    "    倒排融合\n",
    "    \"\"\"\n",
    "    fused_scores = {}\n",
    "\n",
    "    for docs in results:\n",
    "        # 由于原本返回的结果，就是按relvance score排序的，此步可以省略。\n",
    "        # docs = sorted(docs, key=lambda x: x.metadata[\"score\"], reverse=True)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # 计算得分\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "    # 排序\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = (\n",
    "    generate_queries\n",
    "    | retriever_with_score\n",
    "    | reciprocal_rank_fusion\n",
    ")\n",
    "\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)\n",
    "pprint(docs[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1fc665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the provided documents, here is a comprehensive answer to your '\n",
      " 'questions about task decomposition for LLM agents.\\n'\n",
      " '\\n'\n",
      " '### What is Task Decomposition for LLM Agents?\\n'\n",
      " '\\n'\n",
      " 'In the context of LLM-powered autonomous agents, **task decomposition** '\n",
      " '(also referred to as **subgoal decomposition**) is a fundamental planning '\n",
      " 'technique where a large, complex task is broken down into a series of '\n",
      " 'smaller, more manageable subgoals or steps. This allows the agent to tackle '\n",
      " 'problems that are too complicated to solve in a single step efficiently.\\n'\n",
      " '\\n'\n",
      " 'The LLM acts as the agent\\'s \"brain\" and uses this capability to enable the '\n",
      " 'efficient handling of complex tasks by focusing on one achievable step at a '\n",
      " 'time.\\n'\n",
      " '\\n'\n",
      " '### How do LLMs Break Down Complex Tasks? (Methods)\\n'\n",
      " '\\n'\n",
      " 'According to the documents, task decomposition can be achieved through '\n",
      " 'several methods:\\n'\n",
      " '\\n'\n",
      " '1.  **Chain of Thought (CoT):** This is a standard prompting technique where '\n",
      " 'the LLM is instructed to \"think step by step.\" This utilizes more '\n",
      " 'computational power at the time of execution to decompose a hard task into '\n",
      " 'smaller, simpler steps. CoT transforms a large task into multiple manageable '\n",
      " \"ones and provides insight into the model's reasoning process.\\n\"\n",
      " '\\n'\n",
      " '2.  **Tree of Thoughts (ToT):** This method extends CoT by exploring '\n",
      " 'multiple reasoning possibilities at each step. It first decomposes the '\n",
      " 'problem into multiple thought steps and then generates several potential '\n",
      " 'thoughts per step, creating a tree-like structure of options. The agent then '\n",
      " 'searches through these options using strategies like breadth-first search '\n",
      " '(BFS) or depth-first search (DFS), evaluating each potential state with a '\n",
      " 'classifier (via a prompt) or a majority vote.\\n'\n",
      " '\\n'\n",
      " '3.  **Prompting Techniques:** Decomposition can be done by the LLM using '\n",
      " 'simple, direct prompts such as:\\n'\n",
      " '    *   `\"Steps for XYZ.\\\\n1.\"`\\n'\n",
      " '    *   `\"What are the subgoals for achieving XYZ?\"`\\n'\n",
      " '\\n'\n",
      " '4.  **Task-Specific Instructions:** Instructions can be tailored to a '\n",
      " 'specific type of task, for example, instructing the agent to \"Write a story '\n",
      " 'outline.\" as the first step in writing a novel.\\n'\n",
      " '\\n'\n",
      " '5.  **Human Input:** The decomposition process can also be guided or '\n",
      " 'directly provided by a human user.\\n'\n",
      " '\\n'\n",
      " '### Benefits of Task Decomposition\\n'\n",
      " '\\n'\n",
      " 'The primary benefits of task decomposition for LLM agents are:\\n'\n",
      " '\\n'\n",
      " '*   **Efficient Handling of Complexity:** It makes large, complex tasks '\n",
      " 'solvable by dividing them into a sequence of simpler problems.\\n'\n",
      " '*   **Improved Results:** By planning and executing smaller steps, the agent '\n",
      " 'can improve the quality and accuracy of the final outcome. This process is '\n",
      " 'often complemented by self-reflection and refinement, where the agent '\n",
      " 'critiques its past actions, learns from mistakes, and improves future '\n",
      " 'steps.\\n'\n",
      " \"*   **Interpretability:** Techniques like CoT shed light on the model's \"\n",
      " 'internal thinking process, making its reasoning more transparent.\\n'\n",
      " '\\n'\n",
      " '### Challenges\\n'\n",
      " '\\n'\n",
      " 'It is important to note that while powerful, task decomposition is not a '\n",
      " 'solved challenge. The documents note that **long-term planning and task '\n",
      " 'decomposition** remain difficult. LLMs can struggle to adjust plans '\n",
      " 'dynamically when faced with unexpected errors, making them less robust than '\n",
      " 'humans who learn from trial and error.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Output based on questions and reranked documents,\n",
    "questions:\n",
    "{questions}\n",
    "\n",
    "reranked documents:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_rank_fusion_func(docs_with_score):\n",
    "    for rank, (d, s) in enumerate(docs_with_score, 1):\n",
    "        d.page_content = f'doc {rank}, similarity score={s:.2f}, content:\\n\"{d.page_content}\"'\n",
    "    return \"\\n\\n\".join(d.page_content for d, _ in docs_with_score)\n",
    "\n",
    "format_rank_fusion = RunnableLambda(format_rank_fusion_func)\n",
    "\n",
    "final_rag_chain = (\n",
    "    generate_queries\n",
    "    | {\n",
    "        \"context\": retriever_with_score | reciprocal_rank_fusion | format_rank_fusion,\n",
    "        \"questions\": RunnableLambda(lambda x: \"\\n\".join(x))\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = final_rag_chain.invoke({\"question\": question})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66a28e",
   "metadata": {},
   "source": [
    "总结：重新调整了rag-fusion的实现，效果好多了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe938e",
   "metadata": {},
   "source": [
    "# Part 7: 分解 Decomposition\n",
    "整体思路：查询分解的思路更类似于“问题拆解”和“推理”，将原问题分解为多个子问题，依次解决各个子问题，得到最终的答案。\n",
    "\n",
    "Paper:\n",
    "- https://arxiv.org/pdf/2205.10625.pdf\n",
    "- https://arxiv.org/abs/2212.10509.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19be6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Provide these alternative questions separated by newlines. Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3882c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the key architectural components of a Large Language Model (LLM) '\n",
      " 'agent system?',\n",
      " 'How does an autonomous agent system using an LLM for reasoning typically '\n",
      " 'work?',\n",
      " 'What are the main modules or parts that make up an LLM-powered autonomous '\n",
      " 'agent?']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = (\n",
    "    prompt_decomposition\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49bfe84",
   "metadata": {},
   "source": [
    "## 递归地进行回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48384f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f84caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the provided context, the main components of an LLM-powered '\n",
      " 'autonomous agent system are:\\n'\n",
      " '\\n'\n",
      " '1.  **LLM Core (The \"Brain\")**: The Large Language Model functions as the '\n",
      " \"agent's central controller and reasoning engine, processing information and \"\n",
      " 'making decisions.\\n'\n",
      " '\\n'\n",
      " '2.  **Planning**: This component is responsible for:\\n'\n",
      " '    *   **Subgoal and Decomposition**: Breaking down large, complex tasks '\n",
      " 'into smaller, manageable subgoals.\\n'\n",
      " '    *   **Reflection and Refinement**: Engaging in self-criticism and '\n",
      " 'self-reflection on past actions to learn from mistakes and improve future '\n",
      " 'steps and the quality of final results.\\n'\n",
      " '\\n'\n",
      " '3.  **Memory**: This component provides the agent with the capability to '\n",
      " 'retain and recall information, and consists of:\\n'\n",
      " \"    *   **Short-term Memory**: Utilizes the LLM's in-context learning within \"\n",
      " 'its finite context window for immediate processing.\\n'\n",
      " '    *   **Long-term Memory**: Leverages an external vector store and a '\n",
      " 'retrieval system to retain and recall vast amounts of information over '\n",
      " 'extended periods.\\n'\n",
      " '\\n'\n",
      " '4.  **Tool Use**: This enables the agent to call external APIs and tools to '\n",
      " 'access information and capabilities not contained within its pre-trained '\n",
      " 'model weights, such as fetching current information, executing code, or '\n",
      " 'accessing proprietary data sources.\\n'\n",
      " '\\n'\n",
      " 'These components work together, with the LLM core orchestrating the '\n",
      " 'planning, memory, and tool use to enable the agent to operate autonomously.')\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"\n",
    "    格式化问题和答案对\n",
    "    \"\"\"\n",
    "    formatted_string = f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 递归地回答\n",
    "q_a_pairs = \"\"\n",
    "for q in questions + [question]:\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever | format_docs,\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"q_a_pairs\": itemgetter(\"q_a_pairs\"),\n",
    "        }\n",
    "        | decomposition_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    answer = rag_chain.invoke({\"question\": q, \"q_a_pairs\": q_a_pairs})\n",
    "    q_a_pairs += \"\\n---\\n\" + format_qa_pair(q, answer)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168c24e",
   "metadata": {},
   "source": [
    "## 独立回答（可并行）\n",
    "使用asyncio和ainvoke可以实现并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74bd061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "Here is a set of Q+A pairs:\n",
      "\n",
      "{context}\n",
      "\n",
      "Use these to synthesize an answer to the question: {question}\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# RAG prompt\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "print(\"prompt:\")\n",
    "print(prompt.messages[0].prompt.template)\n",
    "print(\"=\"*50)\n",
    "\n",
    "def retrieve_and_rag(question, prompt_rag, sub_question_generator_chain):\n",
    "    \"\"\"子问题进行RAG\"\"\"\n",
    "\n",
    "    # 问题分解\n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\": question})\n",
    "\n",
    "    # 子问题rag\n",
    "    rag_results = []\n",
    "    for sub_question in sub_questions:\n",
    "        retrieved_docs = retriever.invoke(sub_question)\n",
    "\n",
    "        answer = (\n",
    "            prompt_rag\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        answer = answer.invoke({\"context\": format_docs_func(retrieved_docs), \"question\": sub_question})\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results, sub_questions\n",
    "\n",
    "answers, questions = retrieve_and_rag(\n",
    "    question,\n",
    "    prompt_rag,\n",
    "    generate_queries_decomposition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43136195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the provided Q&A pairs, the main components of an LLM-powered '\n",
      " 'autonomous agent system are:\\n'\n",
      " '\\n'\n",
      " '1.  **The LLM Core (Controller/Reasoning Engine):** This is the central '\n",
      " '\"brain\" of the agent. The LLM is responsible for high-level reasoning, '\n",
      " \"decision-making, and controlling the agent's overall actions.\\n\"\n",
      " '\\n'\n",
      " '2.  **Planning Module:** This component handles task decomposition and '\n",
      " 'self-reflection. It breaks down large, complex tasks into manageable '\n",
      " \"subgoals and refines the agent's approach based on outcomes.\\n\"\n",
      " '\\n'\n",
      " '3.  **Memory Module:** This includes both short-term and long-term memory, '\n",
      " 'allowing the agent to retain and recall information across interactions to '\n",
      " 'maintain context and learn from past experiences.\\n'\n",
      " '\\n'\n",
      " '4.  **Tool Use Module:** This enables the agent to interact with external '\n",
      " 'data sources and environments by calling external APIs and functions, '\n",
      " 'greatly expanding its capabilities beyond its built-in knowledge.\\n'\n",
      " '\\n'\n",
      " 'These four components work together, with the LLM core orchestrating the '\n",
      " 'planning, memory, and tool use to enable the agent to operate autonomously.')\n"
     ]
    }
   ],
   "source": [
    "# final answer\n",
    "def format_qa_pairs(question, answer):\n",
    "    \"\"\"\n",
    "    格式化问题和答案对\n",
    "    \"\"\"\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_answer = final_rag_chain.invoke({\"question\": question, \"context\": context})\n",
    "pprint(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf865b79",
   "metadata": {},
   "source": [
    "总结：\n",
    "感觉递归的回答效果要好一些"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf1159",
   "metadata": {},
   "source": [
    "# Part 8: Step Back（回退）\n",
    "之前的策略是使用更“具体”的问题进行检索，这里反其道而行，使用更“抽象”的问题进行检索，能对问题有一个“更高层次”的认识。  \n",
    "Paper  \n",
    "- https://arxiv.org/pdf/2310.06117.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f88eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过few-shots的方式引导LLM提出一个更通用（抽象层次更高）的问题\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "system_prompt = (\n",
    "    \"You are an expert at world knowledge. \"\n",
    "    \"Your task is to step back and paraphrase a question \"\n",
    "    \"to a more generic step-back question, \"\n",
    "    \"which is easier to answer. Here are a few examples:\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{question}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60733428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'What is task decomposition in the context of artificial intelligence?'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 构建处理链\n",
    "generate_queries_step_back = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "# 调用\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "step_back_query = generate_queries_step_back.invoke({\"question\": question})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(step_back_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "777f360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the provided context, **task decomposition for LLM agents** is a '\n",
      " 'core component of the planning module. It is the process by which a Large '\n",
      " 'Language Model (LLM) breaks down a large, complex task into smaller, more '\n",
      " 'manageable subgoals or steps. This enables the autonomous agent to handle '\n",
      " 'tasks that are too complicated to be solved in a single step.\\n'\n",
      " '\\n'\n",
      " 'Here are the key details about task decomposition as described in the '\n",
      " 'context:\\n'\n",
      " '\\n'\n",
      " '1.  **Purpose:** The primary purpose is to enable \"efficient handling of '\n",
      " 'complex tasks.\" By decomposing a task, the agent can tackle it in a '\n",
      " 'structured, step-by-step manner.\\n'\n",
      " '\\n'\n",
      " '2.  **Connection to Known Techniques:** The concept is directly linked to '\n",
      " 'the \"Chain of Thought\" (CoT) prompting technique. The context states that '\n",
      " '\"CoT transforms big tasks into multiple manageable tasks,\" making it a '\n",
      " 'fundamental method for achieving decomposition. It is also extended by more '\n",
      " 'advanced techniques like \"Tree of Thoughts,\" which explores multiple '\n",
      " 'reasoning possibilities for each step.\\n'\n",
      " '\\n'\n",
      " '3.  **Methods of Decomposition:** The context specifies three ways task '\n",
      " 'decomposition can be accomplished:\\n'\n",
      " '    *   **Simple LLM Prompting:** Using instructions like `\"Steps for '\n",
      " 'XYZ.\\\\n1.\"` or `\"What are the subgoals for achieving XYZ?\"`\\n'\n",
      " '    *   **Task-Specific Instructions:** For example, instructing the LLM to '\n",
      " '`\"Write a story outline.\"` as the first step in writing a novel.\\n'\n",
      " '    *   **Human Inputs:** Decomposition can be guided or provided directly '\n",
      " 'by a human.\\n'\n",
      " '\\n'\n",
      " '4.  **Role in the Agent System:** It is identified as a fundamental '\n",
      " 'capability that allows the LLM, which acts as the agent\\'s \"brain,\" to plan '\n",
      " 'and reason. The agent uses this decomposed plan to then select specialized '\n",
      " 'models for each sub-task and execute them in sequence.\\n'\n",
      " '\\n'\n",
      " 'In summary, task decomposition is the strategic fragmentation of a complex '\n",
      " 'objective into simpler, sequential sub-tasks, allowing an LLM-powered agent '\n",
      " 'to plan, reason, and execute effectively. This process is a critical '\n",
      " 'differentiator between using an LLM merely as a text generator and '\n",
      " 'leveraging it as the core controller of an autonomous problem-solving agent.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Response prompt \n",
    "# 按如下的结构构建prompt:\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "# Original Question: {question}\n",
    "# Answer:\n",
    "response_prompt_template = (\n",
    "    \"You are an expert of world knowledge. \"\n",
    "    \"I am going to ask you a original question. Your response \"\n",
    "    \"should be comprehensive and not contradicted \"\n",
    "    \"with the following context if they are relevant. \"\n",
    "    \"Otherwise, ignore them if they are not relevant.\\n\\n\"\n",
    "    \"# {normal_context}\\n\"\n",
    "    \"# {step_back_context}\\n\\n\"\n",
    "    \"# Original Question: {question}\\n\"\n",
    "    \"# Answer:\"\n",
    ")\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "# 构建处理链\n",
    "chain = (\n",
    "    {\n",
    "        # 通过原始问题搜索相关信息\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever | format_docs,\n",
    "        # 通过step back问题搜索相关信息\n",
    "        \"step_back_context\": generate_queries_step_back | retriever | format_docs,\n",
    "        # 原始问题\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "final_answer = chain.invoke({\"question\": question})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107a809",
   "metadata": {},
   "source": [
    "总结：step-back是目前感觉效果最好的方法，且效率也比较高。回答的主要特点就是“全面”，这也是step-back的主要收益，但同时可能也会显得有些“啰嗦”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32daaec1",
   "metadata": {},
   "source": [
    "# Part 9: HyDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1c173",
   "metadata": {},
   "source": [
    "Hypothetical Document Embeddings (HyDE)  \n",
    "主要的思想是，问题和答案可能不在一个嵌入空间，通过生成“假设”文档，让问题和待检索的doc处于同一空间。  \n",
    "具体做法：\n",
    "1. 给定一个查询，HyDE 首先让LLM根据问题生成一个与问题相关的“假设”文档。\n",
    "2. 然后，一个无监督对比学习编码器（例如 Contriever）将该文档编码成一个嵌入向量。\n",
    "3. 根据生成的“假设”文档检索相似的真实文档。  \n",
    "Paper:  \n",
    "- https://arxiv.org/abs/2212.10496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adbf8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Of course. Here is a scientific paper passage answering the question: \"What '\n",
      " 'is task decomposition for LLM agents?\"\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **Task Decomposition in Large Language Model Agents**\\n'\n",
      " '\\n'\n",
      " '**Abstract:** The efficacy of Large Language Model (LLM) agents in complex, '\n",
      " 'multi-step reasoning and problem-solving is fundamentally constrained by '\n",
      " 'their inherent limitations in planning, context window size, and '\n",
      " 'susceptibility to error propagation. To mitigate these constraints, **task '\n",
      " 'decomposition** has emerged as a critical cognitive architectural paradigm. '\n",
      " 'This paper delineates the conceptual framework of task decomposition, its '\n",
      " 'operational methodologies, and its significance in enabling robust agentic '\n",
      " 'behavior.\\n'\n",
      " '\\n'\n",
      " '**1. Introduction**\\n'\n",
      " 'An LLM agent is a system that utilizes a large language model as its core '\n",
      " 'computational engine to perceive its environment, reason over goals, and '\n",
      " 'execute actions autonomously. While powerful, monolithic prompts directing '\n",
      " 'an agent to solve a highly complex task (e.g., \"Develop a full-stack web '\n",
      " 'application\") often lead to coherence breakdown, context overflow, or '\n",
      " 'logical inconsistencies. Task decomposition addresses this by breaking a '\n",
      " 'single, intricate objective into a directed acyclic graph (DAG) of smaller, '\n",
      " 'manageable, and logically sequenced sub-tasks. This process is analogous to '\n",
      " 'hierarchical planning in classical artificial intelligence but is '\n",
      " 'implemented through the linguistic and reasoning capabilities of the LLM '\n",
      " 'itself.\\n'\n",
      " '\\n'\n",
      " '**2. The Framework of Task Decomposition**\\n'\n",
      " 'Formally, task decomposition is the process where an LLM agent, given a '\n",
      " 'high-level goal *G*, generates a set of sub-tasks *{s₁, s₂, ..., sₙ}* such '\n",
      " 'that the sequential or hierarchical execution of these sub-tasks leads to '\n",
      " 'the fulfillment of *G*. This process can be conceptualized in two primary '\n",
      " 'modes:\\n'\n",
      " '\\n'\n",
      " '*   **Implicit Decomposition:** The agent performs decomposition internally '\n",
      " 'within a single reasoning trace. This is often elicited through '\n",
      " 'chain-of-thought (CoT) or least-to-most prompting, where the solution steps '\n",
      " 'are generated as part of a continuous rationale. While efficient for simpler '\n",
      " \"tasks, this approach remains vulnerable to the model's context window \"\n",
      " 'limitations on long-horizon problems.\\n'\n",
      " '*   **Explicit Decomposition:** The agent employs a dedicated \"planner\" '\n",
      " 'module or a recursive prompting strategy to first generate a explicit, '\n",
      " 'structured plan. This plan, often represented as a list or a tree, is then '\n",
      " 'executed by a separate \"actor\" module or in subsequent, isolated LLM calls. '\n",
      " 'Explicit decomposition allows for state tracking, error recovery, and the '\n",
      " 'injection of external feedback between sub-tasks, making it the cornerstone '\n",
      " 'of advanced agentic frameworks.\\n'\n",
      " '\\n'\n",
      " '**3. Methodological Approaches**\\n'\n",
      " \"The implementation of decomposition leverages the LLM's ability to \"\n",
      " 'understand task semantics and dependencies. Common techniques include:\\n'\n",
      " '\\n'\n",
      " '*   **Prompting Strategies:** Direct instructions such as \"First, break down '\n",
      " 'the problem into steps,\" or \"Create a plan before writing code.\"\\n'\n",
      " '*   **Self-Reflection:** The agent is prompted to critique and refine its '\n",
      " 'own initial plan, identifying missing steps or potential bottlenecks before '\n",
      " 'execution begins.\\n'\n",
      " '*   **Tool Use:** The agent utilizes external APIs or functions to aid '\n",
      " 'decomposition. For instance, an agent might use a code analysis tool to '\n",
      " 'understand a codebase before generating a plan to modify it.\\n'\n",
      " '\\n'\n",
      " '**4. Significance and Advantages**\\n'\n",
      " 'The strategic application of task decomposition confers several key '\n",
      " 'advantages to LLM agents:\\n'\n",
      " '\\n'\n",
      " '*   **Mitigation of Context Limits:** By solving sub-tasks individually, the '\n",
      " 'agent only requires the relevant context for the current step, drastically '\n",
      " \"reducing the burden on the model's finite context window.\\n\"\n",
      " '*   **Improved Accuracy and Reliability:** Smaller tasks are less prone to '\n",
      " 'hallucination and logical errors. Errors that do occur are typically '\n",
      " 'localized to a single sub-task, preventing catastrophic failure and enabling '\n",
      " 'targeted recovery through re-planning or human feedback.\\n'\n",
      " '*   **Enhanced Explainability and Control:** A explicit decomposition tree '\n",
      " \"provides a transparent audit trail of the agent's reasoning process, \"\n",
      " \"allowing developers to diagnose failures and understand the agent's \"\n",
      " 'behavior.\\n'\n",
      " '*   **Enablement of Multi-Agent Systems:** Decomposition naturally '\n",
      " 'facilitates the assignment of different sub-tasks to specialized agent '\n",
      " '\"roles\" (e.g., a planner, a coder, a critic), paving the way for '\n",
      " 'collaborative problem-solving.\\n'\n",
      " '\\n'\n",
      " '**5. Conclusion**\\n'\n",
      " 'Task decomposition is not merely a prompting technique but a foundational '\n",
      " 'principle for scaling LLM capabilities beyond simple Q&A. By recursively '\n",
      " 'deconstructing complex goals into atomic operations, LLM agents can overcome '\n",
      " 'their inherent architectural limitations, achieving a level of deliberate, '\n",
      " 'structured, and reliable autonomy that is essential for their deployment in '\n",
      " 'real-world applications. Future research is directed towards improving the '\n",
      " 'robustness of the decomposition process itself, particularly in handling '\n",
      " 'ambiguous instructions and dynamically adapting plans based on environmental '\n",
      " 'feedback.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '**References:**\\n'\n",
      " '[1] Yao, et al. (2023). \"ReAct: Synergizing Reasoning and Acting in Language '\n",
      " 'Models.\" *arXiv preprint arXiv:2210.03629*.\\n'\n",
      " '[2] Zhou, et al. (2022). \"Least-to-Most Prompting Enables Complex Reasoning '\n",
      " 'in Large Language Models.\" *arXiv preprint arXiv:2205.10625*.\\n'\n",
      " '[3] Wu, et al. (2023). \"AutoGen: Enabling Next-Gen LLM Applications via '\n",
      " 'Multi-Agent Conversation.\" *arXiv preprint arXiv:2308.08155*.')\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "### 生成假设文档\n",
    "# 构造提示词\n",
    "template = (\n",
    "    \"Please write a scientific paper passage to answer the question\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Passage:\"\n",
    ")\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"ARK_MODEL\"),\n",
    "    api_key=os.getenv(\"ARK_API_KEY\"),\n",
    "    base_url=os.getenv(\"ARK_API_URL\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 构建处理链\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 获取假设文档\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "hyde_doc = generate_docs_for_retrieval.invoke({\"question\": question})\n",
    "pprint(hyde_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5318b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
      " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
      " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
      " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).')]\n"
     ]
    }
   ],
   "source": [
    "# 使用hyde_doc进行检索\n",
    "retrieval_chain = (\n",
    "    generate_docs_for_retrieval\n",
    "    | retriever\n",
    ")\n",
    "retrieved_docs = retrieval_chain.invoke({\"question\": question})\n",
    "pprint(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9af0e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the provided context, **task decomposition for LLM agents** is the '\n",
      " 'process of breaking down a large, complex task into smaller, more manageable '\n",
      " 'subgoals or steps. This is a core component of the \"Planning\" module in an '\n",
      " 'LLM-powered autonomous agent system.\\n'\n",
      " '\\n'\n",
      " 'The text provides the following key details about task decomposition:\\n'\n",
      " '\\n'\n",
      " '*   **Purpose:** It enables the agent to handle complex tasks efficiently.\\n'\n",
      " '*   **Methods:** It can be achieved in several ways:\\n'\n",
      " '    1.  **Using LLM with simple prompting**, such as \"Steps for XYZ.\\\\n1.\" '\n",
      " 'or \"What are the subgoals for achieving XYZ?\".\\n'\n",
      " '    2.  **By using task-specific instructions**, for example, instructing '\n",
      " 'the agent to \"Write a story outline.\" as a first step to writing a novel.\\n'\n",
      " '    3.  **With human inputs**.\\n'\n",
      " '*   **Related Techniques:** The concept is linked to standard prompting '\n",
      " 'techniques like **Chain of Thought (CoT)**, which instructs the model to '\n",
      " '\"think step by step\" to decompose hard tasks. It is also extended by methods '\n",
      " 'like **Tree of Thoughts (ToT)**, which explores multiple reasoning '\n",
      " 'possibilities at each step of the decomposition.')\n"
     ]
    }
   ],
   "source": [
    "### final answer\n",
    "template = (\n",
    "    \"Answer the following question based on this context:\\n\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Question: {question}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "final_answer = final_rag_chain.invoke({\n",
    "    \"context\": format_docs_func(retrieved_docs),\n",
    "    \"question\": question\n",
    "})\n",
    "pprint(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6ff4b",
   "metadata": {},
   "source": [
    "总结：Hyde感觉效果也还可以，但没有特别好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540bbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
